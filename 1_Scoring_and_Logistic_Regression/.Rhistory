delta_0 <- log(pi_0) -1/2 * log(abs(det_Sigma_0)) -1/2 * sum(t(c(x1 - mu_01, x2 - mu_02)) %*% inv_Sigma_0 %*% c(x1 - mu_01, x2 - mu_02))
delta_1 - delta_0
}
discriminant_boundary_V <- Vectorize(discriminant_boundary)
x <- seq(-6, 6, len = 600)
y <- seq(-6, 6, len = 600)
z <- outer(x, y, discriminant_boundary_V)
# Sampling n data from the given distrib
set.seed(6)
n <- 10000
n1 <- rbinom(1, n, pi_1)
n0 <- n - n1
# Class 1
class_1 <- MASS::mvrnorm(n1, mu_1, Sigma_1)
class_1 <- tibble(Y=1, x1 = class_1[,1], x2 = class_1[,2])
# Class 0
class_0 <- MASS::mvrnorm(n0, mu_0, Sigma_0)
class_0 <- tibble(Y=0, x1 = class_0[,1], x2 = class_0[,2])
# Predict with QDA on a grid
class_dat <- bind_rows(class_1, class_0) %>%
mutate(Y = as.factor(Y))
qda_class <- MASS::qda(Y~x1+x2, data=class_dat)
lda_class <- MASS::lda(Y~x1+x2, data=class_dat)
lda_2nd_class <- MASS::lda(Y~x1+x2+I(x1*x2)+I(x1^2)+I(x2^2), data=class_dat)
logreg_class <- glm(Y~x1+x2+I(x1*x2)+I(x1^2)+I(x2^2), data=class_dat, family="binomial")
density_qda <- expand.grid(x1 = x, x2 = y) %>% as_tibble()
qda_pred <- predict(qda_class, density_qda)
lda_pred <- predict(lda_class, density_qda)
lda_2nd_pred <- predict(lda_2nd_class, density_qda)
logreg_pred <- broom::augment(logreg_class, newdata = density_qda, type.predict = "response")
qda_fit <- tibble(class_qda = as.numeric(as.character(qda_pred$class)),
class_lda = as.numeric(as.character(lda_pred$class)),
class_lda_2nd = as.numeric(as.character(lda_2nd_pred$class)),
class_logreg_2nd = logreg_pred$.fitted) %>%
mutate(class_logreg_2nd = if_else(class_logreg_2nd>0.5, 1, 0))
density_qda <- bind_cols(density_qda, qda_fit)
oracle_qda <- bind_cols(density_qda, tibble(oracle = t(matrix(z, nrow=1))))
ggplot(class_dat) +
geom_point(aes(x=x1, y=x2, colour = Y), alpha = 0.35) +
scale_colour_manual(values = c("dodgerblue", "orange")) +
geom_contour(data = density_qda, aes(x=x1, y=x2, z = class_qda), col = 'darkgrey') +
geom_contour(data = density_qda, aes(x=x1, y=x2, z = class_lda), col = 'darkred') +
geom_contour(data = density_qda, aes(x=x1, y=x2, z = class_lda_2nd), col = 'darkgreen') +
geom_contour(data = density_qda, aes(x=x1, y=x2, z = class_logreg_2nd), col = 'darkblue') +
geom_contour(data = oracle_qda, aes(x=x1, y=x2, z = oracle), breaks = c(0), col = 'purple')
Sigma_1
?rbnorm
??rbnorm
# Class 1 parameters
pi_1 <- 0.5
mu_11 <- 1
mu_12 <- 0
sig_11 <- 1
sig_12 <- sqrt(2)
rho_1 <- 0.8
# Class 0 parameters
pi_0 <- 1- pi_1
mu_01 <- 0
mu_02 <- 3
sig_01 <- sqrt(3)
sig_02 <- 1
rho_0 <- -0.3
# Class 1 helpers
mu_1 <- c(mu_11, mu_12)
Sigma_1 <- matrix(c(sig_11 ^ 2, rho_1 * sig_11 * sig_12, rho_1 * sig_11 * sig_12, sig_12 ^ 2), nrow = 2)
det_Sigma_1 <- sig_11 ^ 2 * sig_12 ^ 2 * (1 - rho_1 ^ 2)
inv_Sigma_1 <- 1 / det_Sigma_1 * matrix(c(sig_12 ^ 2, - rho_1 * sig_11 * sig_12, - rho_1 * sig_11 * sig_12, sig_11 ^ 2), nrow = 2)
# Class 0 helpers
mu_0 <- c(mu_01, mu_02)
Sigma_0 <- matrix(c(sig_01 ^ 2, rho_0 * sig_01 * sig_02, rho_0 * sig_01 * sig_02, sig_02 ^ 2), nrow = 2)
det_Sigma_0  <- sig_01 ^ 2 * sig_02 ^ 2 * (1 - rho_0 ^ 2)
inv_Sigma_0 <- 1 / det_Sigma_0 * matrix(c(sig_02 ^ 2, - rho_0 * sig_01 * sig_02, - rho_0 * sig_01 * sig_02, sig_01 ^ 2), nrow = 2)
# Conic section
A <- sig_12^2/abs(det_Sigma_1)-sig_12^2/abs(det_Sigma_0)
B <- -2 *(rho_1 * sig_11 * sig_12 / abs(det_Sigma_1) - rho_0 * sig_01 * sig_02 / abs(det_Sigma_0) )
C <- sig_11^2/abs(det_Sigma_1)-sig_01^2/abs(det_Sigma_0)
det_conic <- B ^ 2 - 4 * A * C
conic <- "parabola"
if(det_conic>0){
conic <- "hyperbola"
} else if(det_conic<0){
conic <- "ellipse"
}
(paste("decision boundary is an",conic))
# https://stackoverflow.com/questions/74499955/how-to-depict-a-graph-of-an-implicit-differentiation-equation-on-r/74500274#74500274
# Speed up with Rcpp if needed
# https://stackoverflow.com/questions/56765690/efficient-way-of-computing-quadratic-forms-for-outer-product-matrices
discriminant_boundary <- function(x1, x2){
# Boundary decision equation (equalizing the two discriminant equations)
delta_1 <- log(pi_1) -1/2 * log(abs(det_Sigma_1)) -1/2 * sum(t(c(x1 - mu_11, x2 - mu_12)) %*% inv_Sigma_1 %*% c(x1 - mu_11, x2 - mu_12))
delta_0 <- log(pi_0) -1/2 * log(abs(det_Sigma_0)) -1/2 * sum(t(c(x1 - mu_01, x2 - mu_02)) %*% inv_Sigma_0 %*% c(x1 - mu_01, x2 - mu_02))
delta_1 - delta_0
}
discriminant_boundary_V <- Vectorize(discriminant_boundary)
x <- seq(-6, 6, len = 600)
y <- seq(-6, 6, len = 600)
z <- outer(x, y, discriminant_boundary_V)
# Sampling n data from the given distrib
set.seed(6)
n <- 10000
n1 <- rbinom(1, n, pi_1)
n0 <- n - n1
# Class 1
class_1 <- MASS::mvrnorm(n1, mu_1, Sigma_1)
class_1 <- tibble(Y=1, x1 = class_1[,1], x2 = class_1[,2])
# Class 0
class_0 <- MASS::mvrnorm(n0, mu_0, Sigma_0)
class_0 <- tibble(Y=0, x1 = class_0[,1], x2 = class_0[,2])
# Predict with QDA on a grid
class_dat <- bind_rows(class_1, class_0) %>%
mutate(Y = as.factor(Y))
qda_class <- MASS::qda(Y~x1+x2, data=class_dat)
lda_class <- MASS::lda(Y~x1+x2, data=class_dat)
lda_2nd_class <- MASS::lda(Y~x1+x2+I(x1*x2)+I(x1^2)+I(x2^2), data=class_dat)
logreg_class <- glm(Y~x1+x2+I(x1*x2)+I(x1^2)+I(x2^2), data=class_dat, family="binomial")
density_qda <- expand.grid(x1 = x, x2 = y) %>% as_tibble()
qda_pred <- predict(qda_class, density_qda)
lda_pred <- predict(lda_class, density_qda)
lda_2nd_pred <- predict(lda_2nd_class, density_qda)
logreg_pred <- broom::augment(logreg_class, newdata = density_qda, type.predict = "response")
qda_fit <- tibble(class_qda = as.numeric(as.character(qda_pred$class)),
class_lda = as.numeric(as.character(lda_pred$class)),
class_lda_2nd = as.numeric(as.character(lda_2nd_pred$class)),
class_logreg_2nd = logreg_pred$.fitted) %>%
mutate(class_logreg_2nd = if_else(class_logreg_2nd>0.5, 1, 0))
density_qda <- bind_cols(density_qda, qda_fit)
oracle_qda <- bind_cols(density_qda, tibble(oracle = t(matrix(z, nrow=1))))
ggplot(class_dat) +
geom_point(aes(x=x1, y=x2, colour = Y), alpha = 0.35) +
scale_colour_manual(values = c("dodgerblue", "orange")) +
geom_contour(data = density_qda, aes(x=x1, y=x2, z = class_qda), col = 'darkgrey') +
geom_contour(data = density_qda, aes(x=x1, y=x2, z = class_lda), col = 'darkred') +
geom_contour(data = density_qda, aes(x=x1, y=x2, z = class_lda_2nd), col = 'darkgreen') +
geom_contour(data = density_qda, aes(x=x1, y=x2, z = class_logreg_2nd), col = 'darkblue') +
geom_contour(data = oracle_qda, aes(x=x1, y=x2, z = oracle), breaks = c(0), col = 'purple')
set.seed(6)
n <- 10000
n1 <- rbinom(1, n, pi_1)
n0 <- n - n1
n1
?rbinom
rbinom(2,10000, 0.5)
n0
class_1 <- MASS::mvrnorm(n1, mu_1, Sigma_1)
class_1
# Class 1 parameters
pi_1 <- 0.5
mu_11 <- 1
mu_12 <- 0
sig_11 <- 1
sig_12 <- sqrt(2)
rho_1 <- 0.8
# Class 0 parameters
pi_0 <- 1- pi_1
mu_01 <- 0
mu_02 <- 3
sig_01 <- sqrt(3)
sig_02 <- 1
rho_0 <- -0.3
# Class 1 helpers
mu_1 <- c(mu_11, mu_12)
Sigma_1 <- matrix(c(sig_11 ^ 2, rho_1 * sig_11 * sig_12, rho_1 * sig_11 * sig_12, sig_12 ^ 2), nrow = 2)
det_Sigma_1 <- sig_11 ^ 2 * sig_12 ^ 2 * (1 - rho_1 ^ 2)
inv_Sigma_1 <- 1 / det_Sigma_1 * matrix(c(sig_12 ^ 2, - rho_1 * sig_11 * sig_12, - rho_1 * sig_11 * sig_12, sig_11 ^ 2), nrow = 2)
# Class 0 helpers
mu_0 <- c(mu_01, mu_02)
Sigma_0 <- matrix(c(sig_01 ^ 2, rho_0 * sig_01 * sig_02, rho_0 * sig_01 * sig_02, sig_02 ^ 2), nrow = 2)
det_Sigma_0  <- sig_01 ^ 2 * sig_02 ^ 2 * (1 - rho_0 ^ 2)
inv_Sigma_0 <- 1 / det_Sigma_0 * matrix(c(sig_02 ^ 2, - rho_0 * sig_01 * sig_02, - rho_0 * sig_01 * sig_02, sig_01 ^ 2), nrow = 2)
# Conic section
A <- sig_12^2/abs(det_Sigma_1)-sig_12^2/abs(det_Sigma_0)
B <- -2 *(rho_1 * sig_11 * sig_12 / abs(det_Sigma_1) - rho_0 * sig_01 * sig_02 / abs(det_Sigma_0) )
C <- sig_11^2/abs(det_Sigma_1)-sig_01^2/abs(det_Sigma_0)
det_conic <- B ^ 2 - 4 * A * C
conic <- "parabola"
if(det_conic>0){
conic <- "hyperbola"
} else if(det_conic<0){
conic <- "ellipse"
}
(paste("decision boundary is an",conic))
# https://stackoverflow.com/questions/74499955/how-to-depict-a-graph-of-an-implicit-differentiation-equation-on-r/74500274#74500274
# Speed up with Rcpp if needed
# https://stackoverflow.com/questions/56765690/efficient-way-of-computing-quadratic-forms-for-outer-product-matrices
discriminant_boundary <- function(x1, x2){
# Boundary decision equation (equalizing the two discriminant equations)
delta_1 <- log(pi_1) -1/2 * log(abs(det_Sigma_1)) -1/2 * sum(t(c(x1 - mu_11, x2 - mu_12)) %*% inv_Sigma_1 %*% c(x1 - mu_11, x2 - mu_12))
delta_0 <- log(pi_0) -1/2 * log(abs(det_Sigma_0)) -1/2 * sum(t(c(x1 - mu_01, x2 - mu_02)) %*% inv_Sigma_0 %*% c(x1 - mu_01, x2 - mu_02))
delta_1 - delta_0
}
discriminant_boundary_V <- Vectorize(discriminant_boundary)
x <- seq(-6, 6, len = 600)
y <- seq(-6, 6, len = 600)
z <- outer(x, y, discriminant_boundary_V)
# Sampling n data from the given distrib
set.seed(6)
n <- 10000
n1 <- rbinom(1, n, pi_1)
n0 <- n - n1
# Class 1
class_1 <- MASS::mvrnorm(n1, mu_1, Sigma_1)
class_1 <- tibble(Y=1, x1 = class_1[,1], x2 = class_1[,2])
# Class 0
class_0 <- MASS::mvrnorm(n0, mu_0, Sigma_0)
class_0 <- tibble(Y=0, x1 = class_0[,1], x2 = class_0[,2])
# Predict with QDA on a grid
class_dat <- bind_rows(class_1, class_0) %>%
mutate(Y = as.factor(Y))
qda_class <- MASS::qda(Y~x1+x2, data=class_dat)
lda_class <- MASS::lda(Y~x1+x2, data=class_dat)
lda_2nd_class <- MASS::lda(Y~x1+x2+I(x1*x2)+I(x1^2)+I(x2^2), data=class_dat)
logreg_class <- glm(Y~x1+x2+I(x1*x2)+I(x1^2)+I(x2^2), data=class_dat, family="binomial")
density_qda <- expand.grid(x1 = x, x2 = y) %>% as_tibble()
qda_pred <- predict(qda_class, density_qda)
lda_pred <- predict(lda_class, density_qda)
lda_2nd_pred <- predict(lda_2nd_class, density_qda)
logreg_pred <- broom::augment(logreg_class, newdata = density_qda, type.predict = "response")
qda_fit <- tibble(class_qda = as.numeric(as.character(qda_pred$class)),
class_lda = as.numeric(as.character(lda_pred$class)),
class_lda_2nd = as.numeric(as.character(lda_2nd_pred$class)),
class_logreg_2nd = logreg_pred$.fitted) %>%
mutate(class_logreg_2nd = if_else(class_logreg_2nd>0.5, 1, 0))
density_qda <- bind_cols(density_qda, qda_fit)
oracle_qda <- bind_cols(density_qda, tibble(oracle = t(matrix(z, nrow=1))))
ggplot(class_dat) +
geom_point(aes(x=x1, y=x2, colour = Y), alpha = 0.35) +
scale_colour_manual(values = c("dodgerblue", "orange")) +
geom_contour(data = density_qda, aes(x=x1, y=x2, z = class_qda), col = 'darkgrey') +
geom_contour(data = density_qda, aes(x=x1, y=x2, z = class_lda), col = 'darkred') +
geom_contour(data = density_qda, aes(x=x1, y=x2, z = class_lda_2nd), col = 'darkgreen') +
geom_contour(data = density_qda, aes(x=x1, y=x2, z = class_logreg_2nd), col = 'darkblue') +
geom_contour(data = oracle_qda, aes(x=x1, y=x2, z = oracle), breaks = c(0), col = 'purple')
class_1 <- MASS::mvrnorm(n1, mu_1, Sigma_1)
class_1 <- tibble(Y=1, x1 = class_1[,1], x2 = class_1[,2])
class_1
mu_1
Sigma_1
mu_0
Sigma_0
density_qda
density_qda <- expand.grid(x1 = x, x2 = y) %>% as_tibble()
density_qda
qda_pred <- predict(qda_class, density_qda)
qda_pred
?pedict
?predict
density_qda <- expand.grid(x1 = x, x2 = y) %>% as_tibble()
qda_pred <- predict(qda_class, density_qda)
lda_pred <- predict(lda_class, density_qda)
lda_2nd_pred <- predict(lda_2nd_class, density_qda)
logreg_pred <- broom::augment(logreg_class, newdata = density_qda, type.predict = "response")
qda_fit <- tibble(class_qda = as.numeric(as.character(qda_pred$class)),
class_lda = as.numeric(as.character(lda_pred$class)),
class_lda_2nd = as.numeric(as.character(lda_2nd_pred$class)),
class_logreg_2nd = logreg_pred$.fitted) %>%
mutate(class_logreg_2nd = if_else(class_logreg_2nd>0.5, 1, 0))
density_qda <- bind_cols(density_qda, qda_fit)
density_qda
oracle_qda <- bind_cols(density_qda, tibble(oracle = t(matrix(z, nrow=1))))
oracle_qda
?oracle
??oracle
z
?predict_oracle_V
??predict_oracle_V
?matrix
?outer
# Class 1 parameters
pi_1 <- 0.5
mu_11 <- 1
mu_12 <- 0
sig_11 <- 1
sig_12 <- sqrt(2)
rho_1 <- 0.8
# Class 0 parameters
pi_0 <- 1- pi_1
mu_01 <- 0
mu_02 <- 3
sig_01 <- sqrt(3)
sig_02 <- 1
rho_0 <- -0.3
# Class 1 helpers
mu_1 <- c(mu_11, mu_12)
Sigma_1 <- matrix(c(sig_11 ^ 2, rho_1 * sig_11 * sig_12, rho_1 * sig_11 * sig_12, sig_12 ^ 2), nrow = 2)
det_Sigma_1 <- sig_11 ^ 2 * sig_12 ^ 2 * (1 - rho_1 ^ 2)
inv_Sigma_1 <- 1 / det_Sigma_1 * matrix(c(sig_12 ^ 2, - rho_1 * sig_11 * sig_12, - rho_1 * sig_11 * sig_12, sig_11 ^ 2), nrow = 2)
# Class 0 helpers
mu_0 <- c(mu_01, mu_02)
Sigma_0 <- matrix(c(sig_01 ^ 2, rho_0 * sig_01 * sig_02, rho_0 * sig_01 * sig_02, sig_02 ^ 2), nrow = 2)
det_Sigma_0  <- sig_01 ^ 2 * sig_02 ^ 2 * (1 - rho_0 ^ 2)
inv_Sigma_0 <- 1 / det_Sigma_0 * matrix(c(sig_02 ^ 2, - rho_0 * sig_01 * sig_02, - rho_0 * sig_01 * sig_02, sig_01 ^ 2), nrow = 2)
# Conic section
A <- sig_12^2/abs(det_Sigma_1)-sig_12^2/abs(det_Sigma_0)
B <- -2 *(rho_1 * sig_11 * sig_12 / abs(det_Sigma_1) - rho_0 * sig_01 * sig_02 / abs(det_Sigma_0) )
C <- sig_11^2/abs(det_Sigma_1)-sig_01^2/abs(det_Sigma_0)
det_conic <- B ^ 2 - 4 * A * C
conic <- "parabola"
if(det_conic>0){
conic <- "hyperbola"
} else if(det_conic<0){
conic <- "ellipse"
}
(paste("decision boundary is an",conic))
# https://stackoverflow.com/questions/74499955/how-to-depict-a-graph-of-an-implicit-differentiation-equation-on-r/74500274#74500274
# Speed up with Rcpp if needed
# https://stackoverflow.com/questions/56765690/efficient-way-of-computing-quadratic-forms-for-outer-product-matrices
discriminant_boundary <- function(x1, x2){
# Boundary decision equation (equalizing the two discriminant equations)
delta_1 <- log(pi_1) -1/2 * log(abs(det_Sigma_1)) -1/2 * sum(t(c(x1 - mu_11, x2 - mu_12)) %*% inv_Sigma_1 %*% c(x1 - mu_11, x2 - mu_12))
delta_0 <- log(pi_0) -1/2 * log(abs(det_Sigma_0)) -1/2 * sum(t(c(x1 - mu_01, x2 - mu_02)) %*% inv_Sigma_0 %*% c(x1 - mu_01, x2 - mu_02))
delta_1 - delta_0
}
discriminant_boundary_V <- Vectorize(discriminant_boundary)
x <- seq(-6, 6, len = 600)
y <- seq(-6, 6, len = 600)
z <- outer(x, y, discriminant_boundary_V)
# Sampling n data from the given distrib
set.seed(6)
n <- 10000
n1 <- rbinom(1, n, pi_1)
n0 <- n - n1
# Class 1
class_1 <- MASS::mvrnorm(n1, mu_1, Sigma_1)
class_1 <- tibble(Y=1, x1 = class_1[,1], x2 = class_1[,2])
# Class 0
class_0 <- MASS::mvrnorm(n0, mu_0, Sigma_0)
class_0 <- tibble(Y=0, x1 = class_0[,1], x2 = class_0[,2])
# Predict with QDA on a grid
class_dat <- bind_rows(class_1, class_0) %>%
mutate(Y = as.factor(Y))
qda_class <- MASS::qda(Y~x1+x2, data=class_dat)
lda_class <- MASS::lda(Y~x1+x2, data=class_dat)
lda_2nd_class <- MASS::lda(Y~x1+x2+I(x1*x2)+I(x1^2)+I(x2^2), data=class_dat)
logreg_class <- glm(Y~x1+x2+I(x1*x2)+I(x1^2)+I(x2^2), data=class_dat, family="binomial")
density_qda <- expand.grid(x1 = x, x2 = y) %>% as_tibble()
qda_pred <- predict(qda_class, density_qda)
lda_pred <- predict(lda_class, density_qda)
lda_2nd_pred <- predict(lda_2nd_class, density_qda)
logreg_pred <- broom::augment(logreg_class, newdata = density_qda, type.predict = "response")
qda_fit <- tibble(class_qda = as.numeric(as.character(qda_pred$class)),
class_lda = as.numeric(as.character(lda_pred$class)),
class_lda_2nd = as.numeric(as.character(lda_2nd_pred$class)),
class_logreg_2nd = logreg_pred$.fitted) %>%
mutate(class_logreg_2nd = if_else(class_logreg_2nd>0.5, 1, 0))
density_qda <- bind_cols(density_qda, qda_fit)
oracle_qda <- bind_cols(density_qda, tibble(oracle = t(matrix(z, nrow=1))))
ggplot(class_dat) +
geom_point(aes(x=x1, y=x2, colour = Y), alpha = 0.35) +
scale_colour_manual(values = c("dodgerblue", "orange")) +
geom_contour(data = density_qda, aes(x=x1, y=x2, z = class_qda), col = 'darkgrey') +
geom_contour(data = density_qda, aes(x=x1, y=x2, z = class_lda), col = 'darkred') +
geom_contour(data = density_qda, aes(x=x1, y=x2, z = class_lda_2nd), col = 'darkgreen') +
geom_contour(data = density_qda, aes(x=x1, y=x2, z = class_logreg_2nd), col = 'darkblue') +
geom_contour(data = oracle_qda, aes(x=x1, y=x2, z = oracle), breaks = c(0), col = 'purple')
#| code-fold: true
# Class 1 parameters
pi_1 <- 0.5
mu_11 <- 0
mu_12 <- 2
sig_11 <- sqrt(2)
sig_12 <- 1
rho_1 <- 0.8
# Class 0 parameters
pi_0 <- 1- pi_1
mu_01 <- -2
mu_02 <- 0
sig_01 <- sqrt(3)
sig_02 <- sqrt(2)
rho_0 <- -0.3
# Class 1 helpers
mu_1 <- c(mu_11, mu_12)
Sigma_1 <- matrix(c(sig_11 ^ 2, rho_1 * sig_11 * sig_12, rho_1 * sig_11 * sig_12, sig_12 ^ 2), nrow = 2)
det_Sigma_1 <- sig_11 ^ 2 * sig_12 ^ 2 * (1 - rho_1 ^ 2)
inv_Sigma_1 <- 1 / det_Sigma_1 * matrix(c(sig_12 ^ 2, - rho_1 * sig_11 * sig_12, - rho_1 * sig_11 * sig_12, sig_11 ^ 2), nrow = 2)
# Class 0 helpers
mu_0 <- c(mu_01, mu_02)
Sigma_0 <- matrix(c(sig_01 ^ 2, rho_0 * sig_01 * sig_02, rho_0 * sig_01 * sig_02, sig_02 ^ 2), nrow = 2)
det_Sigma_0  <- sig_01 ^ 2 * sig_02 ^ 2 * (1 - rho_0 ^ 2)
inv_Sigma_0 <- 1 / det_Sigma_0 * matrix(c(sig_02 ^ 2, - rho_0 * sig_01 * sig_02, - rho_0 * sig_01 * sig_02, sig_01 ^ 2), nrow = 2)
# Conic section
A <- sig_12^2 / abs(det_Sigma_1) - sig_12^2 / abs(det_Sigma_0)
B <- -2 *(rho_1 * sig_11 * sig_12 / abs(det_Sigma_1) - rho_0 * sig_01 * sig_02 / abs(det_Sigma_0) )
C <- sig_11^2 / abs(det_Sigma_1) - sig_01^2 / abs(det_Sigma_0)
det_conic <- B ^ 2 - 4 * A * C
conic <- "parabola"
if(det_conic>0){
conic <- "hyperbola"
} else if(det_conic<0){
conic <- "ellipse"
}
(paste("decision boundary is an",conic))
# Boundary decision
x <- seq(-6, 6, len = 600)
y <- seq(-6, 6, len = 600)
z <- outer(x, y, Vectorize(discriminant_boundary))
# Sampling n data from the given distrib
set.seed(6)
n <- 10000
n1 <- rbinom(1, n, pi_1)
n0 <- n - n1
# Class 1
class_1 <- MASS::mvrnorm(n1, mu_1, Sigma_1)
class_1 <- tibble(Y=1, x1 = class_1[,1], x2 = class_1[,2])
# Class 0
class_0 <- MASS::mvrnorm(n0, mu_0, Sigma_0)
class_0 <- tibble(Y=0, x1 = class_0[,1], x2 = class_0[,2])
# Predict with QDA on a grid
class_dat <- bind_rows(class_1, class_0) %>%
mutate(Y = as.factor(Y))
qda_class <- MASS::qda(Y~x1+x2, data=class_dat)
lda_class <- MASS::lda(Y~x1+x2, data=class_dat)
lda_2nd_class <- MASS::lda(Y~x1+x2+I(x1*x2)+I(x1^2)+I(x2^2), data=class_dat)
logreg_class <- glm(Y~x1+x2+I(x1*x2)+I(x1^2)+I(x2^2), data=class_dat, family="binomial")
density_qda <- expand.grid(x1 = x, x2 = y) %>% as_tibble()
qda_pred <- predict(qda_class, density_qda)
lda_pred <- predict(lda_class, density_qda)
lda_2nd_pred <- predict(lda_2nd_class, density_qda)
logreg_pred <- broom::augment(logreg_class, newdata = density_qda, type.predict = "response")
qda_fit <- tibble(class_qda = as.numeric(as.character(qda_pred$class)),
class_lda = as.numeric(as.character(lda_pred$class)),
class_lda_2nd = as.numeric(as.character(lda_2nd_pred$class)),
class_logreg_2nd = logreg_pred$.fitted) %>%
mutate(class_logreg_2nd = if_else(class_logreg_2nd>0.5, 1, 0))
density_qda <- bind_cols(density_qda, qda_fit)
oracle_qda <- bind_cols(density_qda, tibble(oracle = t(matrix(z, nrow=1))))
ggplot(class_dat) +
geom_point(aes(x=x1, y=x2, colour = Y), alpha = 0.35) +
scale_colour_manual(values = c("dodgerblue", "orange")) +
geom_contour(data = density_qda, aes(x=x1, y=x2, z = class_qda), col = 'darkgrey') +
geom_contour(data = density_qda, aes(x=x1, y=x2, z = class_lda), col = 'darkred') +
geom_contour(data = density_qda, aes(x=x1, y=x2, z = class_lda_2nd), col = 'darkgreen') +
geom_contour(data = density_qda, aes(x=x1, y=x2, z = class_logreg_2nd), col = 'darkblue') +
geom_contour(data = oracle_qda, aes(x=x1, y=x2, z = oracle), breaks = c(0), col = 'purple')
#| code-fold: true
# Class 1 parameters
pi_1 <- 0.8
mu_11 <- 0
mu_12 <- 0
sig_11 <- 1
sig_12 <- 1
rho_1 <- 0.5
# Class 0 parameters
pi_0 <- 1- pi_1
mu_01 <- 0
mu_02 <- 0
sig_01 <- sqrt(5)
sig_02 <- sqrt(3)
rho_0 <- -0.5
# Class 1 helpers
mu_1 <- c(mu_11, mu_12)
Sigma_1 <- matrix(c(sig_11 ^ 2, rho_1 * sig_11 * sig_12, rho_1 * sig_11 * sig_12, sig_12 ^ 2), nrow = 2)
det_Sigma_1 <- sig_11 ^ 2 * sig_12 ^ 2 * (1 - rho_1 ^ 2)
inv_Sigma_1 <- 1 / det_Sigma_1 * matrix(c(sig_12 ^ 2, - rho_1 * sig_11 * sig_12, - rho_1 * sig_11 * sig_12, sig_11 ^ 2), nrow = 2)
# Class 0 helpers
mu_0 <- c(mu_01, mu_02)
Sigma_0 <- matrix(c(sig_01 ^ 2, rho_0 * sig_01 * sig_02, rho_0 * sig_01 * sig_02, sig_02 ^ 2), nrow = 2)
det_Sigma_0  <- sig_01 ^ 2 * sig_02 ^ 2 * (1 - rho_0 ^ 2)
inv_Sigma_0 <- 1 / det_Sigma_0 * matrix(c(sig_02 ^ 2, - rho_0 * sig_01 * sig_02, - rho_0 * sig_01 * sig_02, sig_01 ^ 2), nrow = 2)
# Conic section
A <- sig_12^2 / abs(det_Sigma_1) - sig_12^2 / abs(det_Sigma_0)
B <- -2 *(rho_1 * sig_11 * sig_12 / abs(det_Sigma_1) - rho_0 * sig_01 * sig_02 / abs(det_Sigma_0) )
C <- sig_11^2 / abs(det_Sigma_1) - sig_01^2 / abs(det_Sigma_0)
det_conic <- B ^ 2 - 4 * A * C
conic <- "parabola"
if(det_conic>0){
conic <- "hyperbola"
} else if(det_conic<0){
conic <- "ellipse"
}
(paste("decision boundary is an",conic))
# Boundary decision
x <- seq(-6, 6, len = 600)
y <- seq(-6, 6, len = 600)
z <- outer(x, y, Vectorize(discriminant_boundary))
# Sampling n data from the given distrib
set.seed(6)
n <- 10000
n1 <- rbinom(1, n, pi_1)
n0 <- n - n1
# Class 1
class_1 <- MASS::mvrnorm(n1, mu_1, Sigma_1)
class_1 <- tibble(Y=1, x1 = class_1[,1], x2 = class_1[,2])
# Class 0
class_0 <- MASS::mvrnorm(n0, mu_0, Sigma_0)
class_0 <- tibble(Y=0, x1 = class_0[,1], x2 = class_0[,2])
# Predict with QDA on a grid
class_dat <- bind_rows(class_1, class_0) %>%
mutate(Y = as.factor(Y))
qda_class <- MASS::qda(Y~x1+x2, data=class_dat)
lda_class <- MASS::lda(Y~x1+x2, data=class_dat)
lda_2nd_class <- MASS::lda(Y~x1+x2+I(x1*x2)+I(x1^2)+I(x2^2), data=class_dat)
logreg_class <- glm(Y~x1+x2+I(x1*x2)+I(x1^2)+I(x2^2), data=class_dat, family="binomial")
density_qda <- expand.grid(x1 = x, x2 = y) %>% as_tibble()
qda_pred <- predict(qda_class, density_qda)
lda_pred <- predict(lda_class, density_qda)
lda_2nd_pred <- predict(lda_2nd_class, density_qda)
logreg_pred <- broom::augment(logreg_class, newdata = density_qda, type.predict = "response")
qda_fit <- tibble(class_qda = as.numeric(as.character(qda_pred$class)),
class_lda = as.numeric(as.character(lda_pred$class)),
class_lda_2nd = as.numeric(as.character(lda_2nd_pred$class)),
class_logreg_2nd = logreg_pred$.fitted) %>%
mutate(class_logreg_2nd = if_else(class_logreg_2nd>0.5, 1, 0))
density_qda <- bind_cols(density_qda, qda_fit)
oracle_qda <- bind_cols(density_qda, tibble(oracle = t(matrix(z, nrow=1))))
ggplot(class_dat) +
geom_point(aes(x=x1, y=x2, colour = Y), alpha = 0.35) +
scale_colour_manual(values = c("dodgerblue", "orange")) +
geom_contour(data = density_qda, aes(x=x1, y=x2, z = class_qda), col = 'darkgrey') +
#geom_contour(data = density_qda, aes(x=x1, y=x2, z = class_lda), col = 'darkred') +
geom_contour(data = density_qda, aes(x=x1, y=x2, z = class_lda_2nd), col = 'darkgreen') +
geom_contour(data = density_qda, aes(x=x1, y=x2, z = class_logreg_2nd), col = 'darkblue') +
geom_contour(data = oracle_qda, aes(x=x1, y=x2, z = oracle), breaks = c(0), col = 'purple')
